{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# En este dataset se desea pronosticar el precio de vhiculos usados. El dataset\n",
    "# original contiene las siguientes columnas:\n",
    "#\n",
    "# - Car_Name: Nombre del vehiculo.\n",
    "# - Year: Año de fabricación.\n",
    "# - Selling_Price: Precio de venta.\n",
    "# - Present_Price: Precio actual.\n",
    "# - Driven_Kms: Kilometraje recorrido.\n",
    "# - Fuel_type: Tipo de combustible.\n",
    "# - Selling_Type: Tipo de vendedor.\n",
    "# - Transmission: Tipo de transmisión.\n",
    "# - Owner: Número de propietarios.\n",
    "#\n",
    "# El dataset ya se encuentra dividido en conjuntos de entrenamiento y prueba\n",
    "# en la carpeta \"files/input/\".\n",
    "#\n",
    "# Los pasos que debe seguir para la construcción de un modelo de\n",
    "# pronostico están descritos a continuación.\n",
    "#\n",
    "#\n",
    "# Paso 1.\n",
    "# Preprocese los datos.\n",
    "# - Cree la columna 'Age' a partir de la columna 'Year'.\n",
    "#   Asuma que el año actual es 2021.\n",
    "# - Elimine las columnas 'Year' y 'Car_Name'.\n",
    "#\n",
    "#\n",
    "# Paso 2.\n",
    "# Divida los datasets en x_train, y_train, x_test, y_test.\n",
    "#\n",
    "#\n",
    "# Paso 3.\n",
    "# Cree un pipeline para el modelo de clasificación. Este pipeline debe\n",
    "# contener las siguientes capas:\n",
    "# - Transforma las variables categoricas usando el método\n",
    "#   one-hot-encoding.\n",
    "# - Escala las variables numéricas al intervalo [0, 1].\n",
    "# - Selecciona las K mejores entradas.\n",
    "# - Ajusta un modelo de regresion lineal.\n",
    "#\n",
    "#\n",
    "# Paso 4.\n",
    "# Optimice los hiperparametros del pipeline usando validación cruzada.\n",
    "# Use 10 splits para la validación cruzada. Use el error medio absoluto\n",
    "# para medir el desempeño modelo.\n",
    "#\n",
    "#\n",
    "# Paso 5.\n",
    "# Guarde el modelo (comprimido con gzip) como \"files/models/model.pkl.gz\".\n",
    "# Recuerde que es posible guardar el modelo comprimido usanzo la libreria gzip.\n",
    "#\n",
    "#\n",
    "# Paso 6.\n",
    "# Calcule las metricas r2, error cuadratico medio, y error absoluto medio\n",
    "# para los conjuntos de entrenamiento y prueba. Guardelas en el archivo\n",
    "# files/output/metrics.json. Cada fila del archivo es un diccionario con\n",
    "# las metricas de un modelo. Este diccionario tiene un campo para indicar\n",
    "# si es el conjunto de entrenamiento o prueba. Por ejemplo:\n",
    "#\n",
    "# {'type': 'metrics', 'dataset': 'train', 'r2': 0.8, 'mse': 0.7, 'mad': 0.9}\n",
    "# {'type': 'metrics', 'dataset': 'test', 'r2': 0.7, 'mse': 0.6, 'mad': 0.8}\n",
    "#\n",
    "\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.compose import ColumnTransformer \n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, median_absolute_error\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import gzip\n",
    "\n",
    "\n",
    "\n",
    "# Paso 1.\n",
    "# Preprocese los datos.\n",
    "# - Cree la columna 'Age' a partir de la columna 'Year'.\n",
    "#   Asuma que el año actual es 2021.\n",
    "# - Elimine las columnas 'Year' y 'Car_Name'.\n",
    "#\n",
    "\n",
    "def preprocess_data(data):\n",
    "    df=data.copy()\n",
    "    df['Age']=2021-df['Year']\n",
    "    df.drop(columns=['Year','Car_Name'],inplace=True)\n",
    "    return df\n",
    "\n",
    "#\n",
    "# Paso 2.\n",
    "# Divida los datasets en x_train, y_train, x_test, y_test.\n",
    "#\n",
    "\n",
    "def get_features_target(data, target_column):\n",
    "    x = data.drop(columns=target_column)\n",
    "    y = data[target_column]\n",
    "    return x, y\n",
    "\n",
    "#\n",
    "# Paso 3.\n",
    "# Cree un pipeline para el modelo de regresión. Este pipeline debe\n",
    "# contener las siguientes capas:\n",
    "# - Transforma las variables categoricas usando el método\n",
    "#   one-hot-encoding.\n",
    "# - Escala las variables numéricas al intervalo [0, 1].\n",
    "# - Selecciona las K mejores entradas.\n",
    "# - Ajusta un modelo de regresion lineal.\n",
    "#\n",
    "\n",
    "def make_pipeline(df):\n",
    "    categorical_features = ['Fuel_Type', 'Selling_type', 'Transmission']\n",
    "    numerical_features = [col for col in df.columns if col not in categorical_features]\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', MinMaxScaler(), numerical_features),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline(\n",
    "        steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('feature_selection', SelectKBest(score_func=f_regression)),\n",
    "            ('regressor', LinearRegression())\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return pipeline\n",
    "#\n",
    "# Paso 4.\n",
    "# Optimice los hiperparametros del pipeline usando validación cruzada.\n",
    "# Use 10 splits para la validación cruzada. Use el error medio absoluto\n",
    "# para medir el desempeño modelo.\n",
    "#\n",
    "\n",
    "def optimize_hyperparameters(pipeline, x_train, y_train):\n",
    "    param_grid = {\n",
    "        'feature_selection__k': [i for i in range(1, 12)]\n",
    "    }\n",
    "\n",
    "    model = GridSearchCV(pipeline, param_grid, cv=10, scoring='neg_mean_absolute_error', n_jobs=-1, verbose=1)\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "#\n",
    "# Paso 5.\n",
    "# Guarde el modelo (comprimido con gzip) como \"files/models/model.pkl.gz\".\n",
    "# Recuerde que es posible guardar el modelo comprimido usanzo la libreria gzip.\n",
    "#\n",
    "#\n",
    "\n",
    "def save_model(model):\n",
    "    if not os.path.exists('../files/models'):\n",
    "        os.makedirs('../files/models')\n",
    "    with gzip.open('../files/models/model.pkl.gz', 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "\n",
    "# Paso 6.\n",
    "# Calcule las metricas r2, error cuadratico medio, y error absoluto medio\n",
    "# para los conjuntos de entrenamiento y prueba. Guardelas en el archivo\n",
    "# files/output/metrics.json. Cada fila del archivo es un diccionario con\n",
    "# las metricas de un modelo. Este diccionario tiene un campo para indicar\n",
    "# si es el conjunto de entrenamiento o prueba. Por ejemplo:\n",
    "#\n",
    "# {'type': 'metrics', 'dataset': 'train', 'r2': 0.8, 'mse': 0.7, 'mad': 0.9}\n",
    "# {'type': 'metrics', 'dataset': 'test', 'r2': 0.7, 'mse': 0.6, 'mad': 0.8}\n",
    "#\n",
    "\n",
    "def calculate_metrics(model, x_train, y_train, x_test, y_test):\n",
    "    y_train_pred = model.predict(x_train)\n",
    "    y_test_pred = model.predict(x_test)\n",
    "\n",
    "    metrics_train = {\n",
    "        'type': 'metrics',\n",
    "        'dataset': 'train',\n",
    "        'r2': float(r2_score(y_train, y_train_pred)),\n",
    "        'mse': float(mean_squared_error(y_train, y_train_pred)),\n",
    "        'mad': float(median_absolute_error(y_train, y_train_pred))\n",
    "    }\n",
    "\n",
    "    metrics_test = {\n",
    "        'type': 'metrics',\n",
    "        'dataset': 'test',\n",
    "        'r2': float(r2_score(y_test, y_test_pred)),\n",
    "        'mse': float(mean_squared_error(y_test, y_test_pred)),\n",
    "        'mad': float(median_absolute_error(y_test, y_test_pred))\n",
    "    }\n",
    "\n",
    "    return metrics_train, metrics_test\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    train_data_zip = '../files/input/train_data.csv.zip'\n",
    "    test_data_zip = '../files/input/test_data.csv.zip'\n",
    "\n",
    "    train_data=pd.read_csv(\n",
    "        train_data_zip,\n",
    "        index_col=False,\n",
    "        compression='zip')\n",
    "\n",
    "    test_data=pd.read_csv(\n",
    "        test_data_zip,\n",
    "        index_col=False,\n",
    "        compression='zip')\n",
    "    \n",
    "    train_data=preprocess_data(train_data)\n",
    "    test_data=preprocess_data(test_data)\n",
    "\n",
    "    x_train, y_train = get_features_target(train_data, 'Present_Price')\n",
    "    x_test, y_test = get_features_target(test_data, 'Present_Price')\n",
    "\n",
    "    pipeline = make_pipeline(x_train)\n",
    "\n",
    "    start = time.time()\n",
    "    model = optimize_hyperparameters(pipeline, x_train, y_train)\n",
    "    end = time.time()\n",
    "\n",
    "    save_model(model)\n",
    "\n",
    "    metrics_train, metrics_test = calculate_metrics(model, x_train, y_train, x_test, y_test)\n",
    "\n",
    "    if not os.path.exists('../files/output'):\n",
    "        os.makedirs('../files/output')\n",
    "\n",
    "    metrics = [metrics_train, metrics_test]\n",
    "    pd.DataFrame(metrics).to_json('../files/output/metrics.json', orient='records', lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
